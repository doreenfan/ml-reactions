{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignition Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maestrobubble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is the path to your data files\n",
    "data_path = '../data/bubble_2spec/'\n",
    "\n",
    "# These is the input/output prefix of your datafile names.\n",
    "input_prefix = 'react_inputs_*'\n",
    "output_prefix = 'react_outputs_*'\n",
    "\n",
    "# Plotfile prefixes, used for visualization purposes.\n",
    "plotfile_prefix = 'plt_*'\n",
    "\n",
    "# By default, this package will save your model, logs of the training and testing data during training,\n",
    "# and plots to a directory. Here you specify that directory.\n",
    "output_dir = 'testing123/'\n",
    "\n",
    "# The log file. Everything that is printed during training also goes into this file in case something\n",
    "# gets interrupted.\n",
    "log_file = output_dir + \"log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first remove the directory we just generated. If you don't do this you'll get an error. This is to protect\n",
    "# this package from overwriting your data in case one forgets to change the output_dir when training a new model\n",
    "\n",
    "!rm -r testing123/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maestrobubble.train import NuclearReactionML\n",
    "nrml = NuclearReactionML(data_path, input_prefix, output_prefix, plotfile_prefix,\n",
    "                output_dir, log_file, DEBUG_MODE=True, DO_PLOTTING=True,\n",
    "                SAVE_MODEL=True, DO_HYPER_OPTIMIZATION=False, LOG_MODE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the package provides preset networks to use\n",
    "from maestrobubble.networks import *\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "def selectModel(model_id = 1):\n",
    "    if model_id == 1:\n",
    "        model = Net_tanh(4, 32, 32, 32, 3)\n",
    "    elif model_id == 2:\n",
    "        model = U_Net(4, 32, 16, 16, 32, 3)\n",
    "    elif model_id == 3:\n",
    "        model = ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 4:\n",
    "        model = Cross_ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 5:\n",
    "        # model = Deep_Net(4, 12, 12, 12, 12, 12, 12, 12, 3)\n",
    "        # model = Combine_Net3(4, 16, 8, 8, 8, 8, 8, 8, 8, 8, 16, 3)\n",
    "        model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "    else:\n",
    "        model = Net(4, 16, 16, 16, 3)\n",
    "    # get model to cuda if possible\n",
    "    model.to(device=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model_id, model_path):\n",
    "    if model_id == 1:\n",
    "        model = Net_tanh(4, 32, 32, 32, 3)\n",
    "    elif model_id == 2:\n",
    "        model = U_Net(4, 32, 16, 16, 32, 3)\n",
    "    elif model_id == 3:\n",
    "        model = ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 4:\n",
    "        model = Cross_ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 5:\n",
    "        # model = Deep_Net(4, 12, 12, 12, 12, 12, 12, 12, 3)\n",
    "        model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "    else:\n",
    "        model = Net(4, 16, 16, 16, 3)\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    except RuntimeError:\n",
    "        model.module.load_state_dict(torch.load(model_path))\n",
    "    print(model)\n",
    "\n",
    "    # get model to cuda if possible\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more complicated loss function with physics constraints\n",
    "from maestrobubble.losses import log_loss, logX_loss, loss_mass_fraction_sum_L\n",
    "import torch.nn as nn\n",
    "\n",
    "def criterion(pred, target): \n",
    "    #loss1 = logX_loss(pred, target, nnuc=2)\n",
    "    #loss2 = 10*loss_mass_fraction_sum_L(pred, totsum=0.3, nnuc=2)\n",
    "    \n",
    "    L = nn.MSELoss()\n",
    "    F = nn.L1Loss()\n",
    "    return L(pred[:, :3], target[:, :3]) + F(torch.sign(pred[:,2]), torch.sign(target[:,2]))\n",
    "    #return loss1 #+ loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def moveData(model_id):\n",
    "    subdir = output_dir + \"model\" + str(model_id) + \"/\"\n",
    "    os.mkdir(subdir)\n",
    "    shutil.move(output_dir + \"component_losses_test.txt\", subdir + \"component_losses_test.txt\")\n",
    "    shutil.move(output_dir + \"component_testing_loss.png\", subdir + \"component_testing_loss.png\")\n",
    "    shutil.move(output_dir + \"component_losses_train.txt\", subdir + \"component_losses_train.txt\")\n",
    "    shutil.move(output_dir + \"component_training_loss.png\", subdir + \"component_training_loss.png\")\n",
    "    shutil.move(output_dir + \"cost_per_epoch.txt\", subdir + \"cost_per_epoch.txt\")\n",
    "    shutil.move(output_dir + \"cost_vs_epoch.png\", subdir + \"cost_vs_epoch.png\")\n",
    "    shutil.move(output_dir + \"my_model.pt\", subdir + \"my_model.pt\")\n",
    "    shutil.move(output_dir + \"prediction_vs_solution_log.png\", subdir + \"prediction_vs_solution_log.png\")\n",
    "    shutil.move(output_dir + \"prediction_vs_solution.png\", subdir + \"prediction_vs_solution.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(1,6):\n",
    "    clear_output()\n",
    "    print(f\"Model {i} \\n\")\n",
    "    \n",
    "    model = selectModel(i)\n",
    "#     model_path = \"testing123/model\" + str(i) + \"/my_model.pt\"\n",
    "#     model = loadModel(i, model_path)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    nrml.train(model, optimizer, num_epochs, criterion)\n",
    "    \n",
    "    # need to put model on cpu for plotting\n",
    "    #model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "    nrml.plot()\n",
    "    \n",
    "    moveData(i)\n",
    "    !rm -r testing123/intermediate_output/\n",
    "    \n",
    "# !mv testing123 testing123_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model (option)\n",
    "from maestrobubble.networks import Net_tanh, Cross_ResNet, Deep_ResNet, Combine_Net3, U_Net\n",
    "import torch\n",
    "\n",
    "model_path = \"testing123/\" + \"my_model.pt\"\n",
    "#model = Net_tanh(5, 16, 16, 16, 16, 4)\n",
    "#model = Cross_ResNet(5, 16, 16, 16, 16, 4)\n",
    "#model = Deep_ResNet(5, 8, 8, 8, 8, 8, 8, 8, 8, 4)\n",
    "#model = Combine_Net3(4, 16, 8, 8, 8, 8, 8, 8, 8, 8, 16, 3)\n",
    "model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "#model = Net_tanh(5, 32, 64, 32, 4)\n",
    "#model = U_Net(4, 32, 8, 8, 16, 3)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more complicated loss function with physics constraints\n",
    "from maestrobubble.losses import logX_loss, loss_mass_fraction_sum_L\n",
    "import torch.nn as nn\n",
    "\n",
    "def criterion(pred, target): \n",
    "    #loss1 = logX_loss(pred, target)\n",
    "    loss2 = 10*loss_mass_fraction_sum_L(pred, totsum=0.3, nnuc=2)\n",
    "    \n",
    "    L = nn.MSELoss()\n",
    "    F = nn.L1Loss()\n",
    "    return loss2 + L(pred[:, :3], target[:, :3]) + F(torch.sign(pred[:,2]), torch.sign(target[:,2]))\n",
    "    #return loss1 #+ loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "# get model to cuda if possible\n",
    "model.to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "nrml.train(model, optimizer, num_epochs, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put model on cpu for plotting\n",
    "#model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "nrml.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "plots = glob.glob('testing123/*.png')\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for plot in plots:\n",
    "    fig = Image(filename=(plot))\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch script\n",
    "net_module = torch.jit.script(model)\n",
    "net_module.save(\"ts_model.pt\")\n",
    "print(net_module.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.cla()\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))\n",
    "print(colors.shape)\n",
    "colors = np.tile(colors, (2,1))\n",
    "print(colors)\n",
    "x = [[2, 3, 6], [4, 4, 5]]\n",
    "y = [[1, 2, 5], [3, 3, 3]]\n",
    "plt.scatter(x, y, c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(nrml.train_loader))\n",
    "print(f\"Data batch shape: {data.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=torch.device(\"cpu\"))\n",
    "pred = model(data)\n",
    "print(f\"Prediction batch shape: {pred.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2.0/torch.log(torch.tensor([0.8, 10**-12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2.0/torch.log(torch.tensor([-0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "iout = [i for i in range(4)]\n",
    "iout = [0, 2, 3]\n",
    "x = np.array([0, 1, 2, 3, 4])\n",
    "xt = torch.from_numpy(x)\n",
    "xt[iout]\n",
    "xt.to(device=torch.device(\"cuda:0\"))\n",
    "print(f\"GPU {torch.cuda.current_device()} of {torch.cuda.device_count()} available devices\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xt)\n",
    "xt = xt.to(dtype=torch.float)\n",
    "xt.reshape((1,xt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
