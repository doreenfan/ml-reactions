{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignition Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maestrobubble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is the path to your data files\n",
    "data_path = '../data/bubble_noneutrino_2spec/'\n",
    "\n",
    "# These is the input/output prefix of your datafile names.\n",
    "input_prefix = 'react_inputs_*'\n",
    "output_prefix = 'react_outputs_*'\n",
    "\n",
    "# Plotfile prefixes, used for visualization purposes.\n",
    "plotfile_prefix = 'plt_*'\n",
    "\n",
    "# By default, this package will save your model, logs of the training and testing data during training,\n",
    "# and plots to a directory. Here you specify that directory.\n",
    "output_dir = 'testing123/'\n",
    "\n",
    "# The log file. Everything that is printed during training also goes into this file in case something\n",
    "# gets interrupted.\n",
    "log_file = output_dir + \"log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first remove the directory we just generated. If you don't do this you'll get an error. This is to protect\n",
    "# this package from overwriting your data in case one forgets to change the output_dir when training a new model\n",
    "\n",
    "!rm -r testing123/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model starting on : 03/07/2022 21:45:16\n",
      "input_prefix react_inputs_*\n",
      "output_prefix react_outputs_*\n",
      "output_dir testing123/\n",
      "DEBUG_MODE False\n",
      "DO_PLOTTING True\n",
      "DO_HYPER_OPTIMIZATION False\n",
      "Loading Input Files...\n",
      "Loading Output Files...\n",
      "Loaded data successfully!\n"
     ]
    }
   ],
   "source": [
    "from maestrobubble.train import NuclearReactionML\n",
    "nrml = NuclearReactionML(data_path, input_prefix, output_prefix, plotfile_prefix,\n",
    "                output_dir, log_file, DEBUG_MODE=False, DO_PLOTTING=True,\n",
    "                SAVE_MODEL=True, DO_HYPER_OPTIMIZATION=False, LOG_MODE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# the package provides preset networks to use\n",
    "from maestrobubble.networks import *\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "def selectModel(model_id = 1):\n",
    "    if model_id == 1:\n",
    "        model = Net_tanh(4, 32, 32, 32, 3)\n",
    "    elif model_id == 2:\n",
    "        model = U_Net(4, 32, 16, 16, 32, 3)\n",
    "    elif model_id == 3:\n",
    "        model = ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 4:\n",
    "        model = Cross_ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 5:\n",
    "        # model = Deep_Net(4, 12, 12, 12, 12, 12, 12, 12, 3)\n",
    "        # model = Combine_Net3(4, 16, 8, 8, 8, 8, 8, 8, 8, 8, 16, 3)\n",
    "        model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "    else:\n",
    "        model = Net(4, 16, 16, 16, 3)\n",
    "    # get model to cuda if possible\n",
    "    model.to(device=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model_id, model_path):\n",
    "    if model_id == 1:\n",
    "        model = Net_tanh(4, 32, 32, 32, 3)\n",
    "    elif model_id == 2:\n",
    "        model = U_Net(4, 32, 16, 16, 32, 3)\n",
    "    elif model_id == 3:\n",
    "        model = ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 4:\n",
    "        model = Cross_ResNet(4, 16, 32, 32, 16, 3)\n",
    "    elif model_id == 5:\n",
    "        # model = Deep_Net(4, 12, 12, 12, 12, 12, 12, 12, 3)\n",
    "        model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "    else:\n",
    "        model = Net(4, 16, 16, 16, 3)\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    except RuntimeError:\n",
    "        model.module.load_state_dict(torch.load(model_path))\n",
    "    print(model)\n",
    "\n",
    "    # get model to cuda if possible\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more complicated loss function with physics constraints\n",
    "from maestrobubble.losses import log_loss, logX_loss, loss_mass_fraction_sum_L\n",
    "import torch.nn as nn\n",
    "\n",
    "def criterion(pred, target): \n",
    "    #loss1 = logX_loss(pred, target, nnuc=2)\n",
    "    #loss2 = 10*loss_mass_fraction_sum_L(pred, totsum=0.3, nnuc=2)\n",
    "    \n",
    "    L = nn.MSELoss()\n",
    "    F = nn.L1Loss()\n",
    "    return L(pred[:, :3], target[:, :3]) + F(torch.sign(pred[:,2]), torch.sign(target[:,2]))\n",
    "    #return loss1 #+ loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def moveData(model_id):\n",
    "    subdir = output_dir + \"model\" + str(model_id) + \"/\"\n",
    "    os.mkdir(subdir)\n",
    "    shutil.move(output_dir + \"component_losses_test.txt\", subdir + \"component_losses_test.txt\")\n",
    "    shutil.move(output_dir + \"component_testing_loss.png\", subdir + \"component_testing_loss.png\")\n",
    "    shutil.move(output_dir + \"component_losses_train.txt\", subdir + \"component_losses_train.txt\")\n",
    "    shutil.move(output_dir + \"component_training_loss.png\", subdir + \"component_training_loss.png\")\n",
    "    shutil.move(output_dir + \"cost_per_epoch.txt\", subdir + \"cost_per_epoch.txt\")\n",
    "    shutil.move(output_dir + \"cost_vs_epoch.png\", subdir + \"cost_vs_epoch.png\")\n",
    "    shutil.move(output_dir + \"my_model.pt\", subdir + \"my_model.pt\")\n",
    "    shutil.move(output_dir + \"prediction_vs_solution_log.png\", subdir + \"prediction_vs_solution_log.png\")\n",
    "    shutil.move(output_dir + \"prediction_vs_solution.png\", subdir + \"prediction_vs_solution.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 \n",
      "\n",
      "Cost at epoch 0 is 0.6699403848409934\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(0,6):\n",
    "    clear_output()\n",
    "    print(f\"Model {i} \\n\")\n",
    "    \n",
    "    model = selectModel(i)\n",
    "#     model_path = \"testing123/model\" + str(i) + \"/my_model.pt\"\n",
    "#     model = loadModel(i, model_path)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    nrml.train(model, optimizer, num_epochs, criterion)\n",
    "    \n",
    "    # need to put model on cpu for plotting\n",
    "    #model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "    nrml.plot()\n",
    "    \n",
    "    moveData(i)\n",
    "    !rm -r testing123/intermediate_output/\n",
    "    \n",
    "# !mv testing123 testing123_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine_Net3(\n",
      "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (ac1): Tanh()\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (ac2): Tanh()\n",
      "  (fc3): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac3): Tanh()\n",
      "  (fc4): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac4): Tanh()\n",
      "  (fc5): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac5): Tanh()\n",
      "  (fc6): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac6): Tanh()\n",
      "  (fc7): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac7): Tanh()\n",
      "  (fc8): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac8): Tanh()\n",
      "  (fc9): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (ac9): Tanh()\n",
      "  (fc10): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (ac10): Tanh()\n",
      "  (fc11): Linear(in_features=16, out_features=3, bias=True)\n",
      "  (fc1to4): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3to6): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (fc5to8): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (fc7to10): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (fc1to10): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (fcio): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load model (option)\n",
    "from maestrobubble.networks import Net_tanh, Cross_ResNet, Deep_ResNet, Combine_Net3, U_Net\n",
    "import torch\n",
    "\n",
    "model_path = \"testing123/\" + \"my_model.pt\"\n",
    "#model = Net_tanh(5, 16, 16, 16, 16, 4)\n",
    "#model = Cross_ResNet(5, 16, 16, 16, 16, 4)\n",
    "#model = Deep_ResNet(5, 8, 8, 8, 8, 8, 8, 8, 8, 4)\n",
    "#model = Combine_Net3(4, 16, 8, 8, 8, 8, 8, 8, 8, 8, 16, 3)\n",
    "model = Combine_Net3(4, 32, 16, 8, 8, 8, 8, 8, 8, 16, 32, 3)\n",
    "#model = Net_tanh(5, 32, 64, 32, 4)\n",
    "#model = U_Net(4, 32, 8, 8, 16, 3)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more complicated loss function with physics constraints\n",
    "from maestrobubble.losses import logX_loss, loss_mass_fraction_sum_L\n",
    "import torch.nn as nn\n",
    "\n",
    "def criterion(pred, target): \n",
    "    #loss1 = logX_loss(pred, target)\n",
    "    loss2 = 10*loss_mass_fraction_sum_L(pred, totsum=0.3, nnuc=2)\n",
    "    \n",
    "    L = nn.MSELoss()\n",
    "    F = nn.L1Loss()\n",
    "    return loss2 + L(pred[:, :3], target[:, :3]) + F(torch.sign(pred[:,2]), torch.sign(target[:,2]))\n",
    "    #return loss1 #+ loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "# get model to cuda if possible\n",
    "model.to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "nrml.train(model, optimizer, num_epochs, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting...\n"
     ]
    }
   ],
   "source": [
    "# need to put model on cpu for plotting\n",
    "#model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "nrml.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "plots = glob.glob('testing123/*.png')\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for plot in plots:\n",
    "    fig = Image(filename=(plot))\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  x1 = (self.ac1).forward((self.fc1).forward(x, ), )\n",
      "  x2 = (self.ac2).forward((self.fc2).forward(x1, ), )\n",
      "  x3 = (self.ac3).forward((self.fc3).forward(x2, ), )\n",
      "  _0 = self.ac4\n",
      "  _1 = torch.add((self.fc4).forward(x3, ), (self.fc1to4).forward(x1, ))\n",
      "  x4 = (_0).forward(_1, )\n",
      "  x5 = (self.ac5).forward((self.fc5).forward(x4, ), )\n",
      "  _2 = self.ac6\n",
      "  _3 = torch.add((self.fc6).forward(x5, ), (self.fc3to6).forward(x3, ))\n",
      "  x6 = (_2).forward(_3, )\n",
      "  x7 = (self.ac7).forward((self.fc7).forward(x6, ), )\n",
      "  _4 = self.ac8\n",
      "  _5 = torch.add((self.fc8).forward(x7, ), (self.fc5to8).forward(x5, ))\n",
      "  x8 = (_4).forward(_5, )\n",
      "  x9 = (self.ac9).forward((self.fc9).forward(x8, ), )\n",
      "  _6 = self.ac10\n",
      "  _7 = torch.add((self.fc10).forward(x9, ), (self.fc7to10).forward(x7, ))\n",
      "  _8 = torch.add(_7, (self.fc1to10).forward(x1, ))\n",
      "  x10 = (_6).forward(_8, )\n",
      "  x11 = torch.add((self.fc11).forward(x10, ), (self.fcio).forward(x, ))\n",
      "  return x11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to torch script\n",
    "net_module = torch.jit.script(model)\n",
    "net_module.save(\"ts_model.pt\")\n",
    "print(net_module.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.cla()\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))\n",
    "print(colors.shape)\n",
    "colors = np.tile(colors, (2,1))\n",
    "print(colors)\n",
    "x = [[2, 3, 6], [4, 4, 5]]\n",
    "y = [[1, 2, 5], [3, 3, 3]]\n",
    "plt.scatter(x, y, c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(nrml.train_loader))\n",
    "print(f\"Data batch shape: {data.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=torch.device(\"cpu\"))\n",
    "pred = model(data)\n",
    "print(f\"Prediction batch shape: {pred.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2.0/torch.log(torch.tensor([0.8, 10**-12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2.0/torch.log(torch.tensor([-0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 of 1 available devices\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "iout = [i for i in range(4)]\n",
    "iout = [0, 2, 3]\n",
    "x = np.array([0, 1, 2, 3, 4])\n",
    "xt = torch.from_numpy(x)\n",
    "xt[iout]\n",
    "xt.to(device=torch.device(\"cuda:0\"))\n",
    "print(f\"GPU {torch.cuda.current_device()} of {torch.cuda.device_count()} available devices\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xt)\n",
    "xt = xt.to(dtype=torch.float)\n",
    "xt.reshape((1,xt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
