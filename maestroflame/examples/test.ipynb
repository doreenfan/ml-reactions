{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maestroflame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is the path to your data files\n",
    "data_path = '../data/flame/'\n",
    "\n",
    "# These is the input/output prefix of your datafile names.\n",
    "input_prefix = 'react_inputs_*'\n",
    "output_prefix = 'react_outputs_*'\n",
    "\n",
    "# Plotfile prefixes, used for visualization purposes.\n",
    "plotfile_prefix = 'flame_*'\n",
    "\n",
    "# By default, this package will save your model, logs of the training and testing data during training,\n",
    "# and plots to a directory. Here you specify that directory.\n",
    "output_dir = 'testing123/'\n",
    "\n",
    "# The log file. Everything that is printed during training also goes into this file in case something\n",
    "# gets interrupted.\n",
    "log_file = output_dir + \"log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first remove the directory we just generated. If you don't do this you'll get an error. This is to protect\n",
    "# this package from overwriting your data in case one forgets to change the output_dir when training a new model\n",
    "\n",
    "!rm -r testing123/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maestroflame.train import NuclearReactionML\n",
    "nrml = NuclearReactionML(data_path, input_prefix, output_prefix, plotfile_prefix,\n",
    "                output_dir, log_file, DEBUG_MODE=False, DO_PLOTTING=True,\n",
    "                SAVE_MODEL=True, DO_HYPER_OPTIMIZATION=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the package provides preset up loss functions and networks to use\n",
    "from maestroflame.losses import log_loss, log_loss_2\n",
    "from maestroflame.networks import Net\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 200\n",
    "model = Net(16, 16, 16, 16, 14)\n",
    "\n",
    "# get model to cuda if possible\n",
    "model.to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "nrml.train(model, optimizer, num_epochs, log_loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put model on cpu for plotting\n",
    "model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "nrml.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "plots = glob.glob('testing123/*.png')\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for plot in plots:\n",
    "    fig = Image(filename=(plot))\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(nrml.train_loader))\n",
    "print(f\"Data batch shape: {data.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=torch.device(\"cpu\"))\n",
    "pred = model(data)\n",
    "print(f\"Prediction batch shape: {pred.size()}\")\n",
    "print(f\"Targets batch shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import numpy as np\n",
    "ds = yt.load(\"../data/flame/react_inputs_0000010_1\")\n",
    "dt = ds.current_time.to_value()\n",
    "yloc = yt.YTArray(2.8, 'cm')\n",
    "# print(ds.r[0.3:0.35,0:yloc])\n",
    "ad = ds.r[0.3:0.31, 0:yloc]\n",
    "for i,field in enumerate(ds._field_list):\n",
    "    if i == 0:\n",
    "        data = np.zeros([len(ds._field_list), len(ad[field])])\n",
    "        data[i,:] = np.array(ad[field])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "fields = [field for field in yt.load(\"../data/flame/react_outputs_0000010_1\")._field_list]\n",
    "# print(fields)\n",
    "\n",
    "nnuc = len(fields)-1\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, nnuc+1))\n",
    "plt.clf()\n",
    "with torch.no_grad():\n",
    "    for i in range(pred.shape[0]):\n",
    "        if i == 0:\n",
    "            for j in range(pred.shape[1]):\n",
    "                plt.scatter(pred[i,j], targets[i,j], \n",
    "                                color=colors[j], label=fields[j])\n",
    "        else:\n",
    "            plt.scatter(pred[i, :], targets[i,:nnuc+1], c=colors)\n",
    "    plt.plot(np.linspace(0, 1), np.linspace(0,1), '--', color='orange')\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "i = np.where(x<0)[0]\n",
    "print(i)\n",
    "x = [0, 3]+list(range(5,13))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_heaviside(x, input):\n",
    "    y = torch.zeros_like(x)\n",
    "    y[x < 0] = 0\n",
    "    y[x > 0] = 1\n",
    "    y[x == 0] = input\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def log_loss_spec(prediction, target):\n",
    "    # Log Loss Function for all species except C12[1], O16[2], Mg24[4]\n",
    "    # If there are negative values in X we use MSE\n",
    "    # Enuc stays with MSE because its normalized\n",
    "\n",
    "    # species that use linear loss\n",
    "    spec_lin = [1, 2, 4]\n",
    "    # species that use log loss\n",
    "    spec_log = [0, 3] + list(range(5,13))\n",
    "\n",
    "    # X is not allowed to be negative. Enuc is\n",
    "    X_lin, X_log = prediction[:, spec_lin], prediction[:, spec_log]\n",
    "    X_lin_target, X_log_target = target[:, spec_lin], target[:, spec_log]\n",
    "    enuc = prediction[:, 13]\n",
    "    enuc_target = target[:, 13]\n",
    "\n",
    "    L = nn.MSELoss()\n",
    "\n",
    "    enuc_loss = L(enuc, enuc_target)\n",
    "\n",
    "\n",
    "    # we want to penalize negative numbers for\n",
    "    # species that use linear loss\n",
    "    if torch.sum(X_lin < 0) > 0:\n",
    "        # how much do we hate negative numbers?\n",
    "        factor = 1000 # a lot\n",
    "\n",
    "        value = torch.tensor([0.], device=device)\n",
    "\n",
    "        # greater than zero we apply mse loss\n",
    "        A = my_heaviside(X_lin, value)\n",
    "\n",
    "        # less than zero we apply large mse loss\n",
    "        B = -my_heaviside(X_lin, value) + 1\n",
    "\n",
    "        linear_loss =  torch.sum(A * L(X_lin, X_lin_target) + factor * B * L(X_lin, X_lin_target))\n",
    "\n",
    "    else:\n",
    "        linear_loss = L(X_lin, X_lin_target)\n",
    "\n",
    "\n",
    "    # if there are negative numbers we cant use log on mass fractions\n",
    "    if torch.sum(X_log < 0) > 0:\n",
    "        # how much do we hate negative log numbers?\n",
    "        factor = 10e6 # a lot a lot\n",
    "\n",
    "        log_loss = factor * L(X_log, X_log_target)\n",
    "\n",
    "    else:\n",
    "        log_loss = torch.abs(.01*L(torch.log(X_log), torch.log(X_log_target)))\n",
    "\n",
    "\n",
    "    return enuc_loss + linear_loss + log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_lin = [1, 2, 4]\n",
    "spec_log = [0, 3] + list(range(5,13))\n",
    "\n",
    "X_lin, X_log = pred[:, spec_lin], pred[:, spec_log]\n",
    "X_lin_target, X_log_target = targets[:, spec_lin], targets[:, spec_log]\n",
    "\n",
    "A = my_heaviside(X_log, torch.tensor([0.]))\n",
    "B = -my_heaviside(X_log, torch.tensor([0.])) + 1\n",
    "print(A * X_log)\n",
    "print(B * X_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_spec(pred, targets)\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The pinn class has the exact same interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/flame_rhs/'\n",
    "input_prefix = 'react_inputs_*'\n",
    "output_prefix = 'react_outputs_*'\n",
    "plotfile_prefix = 'flame_*'\n",
    "output_dir = 'testing123/'\n",
    "log_file = output_dir + \"log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first remove the directory we just generated. If you don't do this you'll get an error. This is to protect\n",
    "# this package from overwriting your data in case one forgets to change the output_dir when training a new model\n",
    "!rm -r testing123/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maestroflame.train import NuclearReactionPinn\n",
    "nrml = NuclearReactionPinn(data_path, input_prefix, output_prefix, plotfile_prefix,\n",
    "                output_dir, log_file, DEBUG_MODE=False, DO_PLOTTING=True,\n",
    "                SAVE_MODEL=True, DO_HYPER_OPTIMIZATION=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A much more complicated loss function\n",
    "\n",
    "import torch.nn as nn\n",
    "from maestroflame.losses import component_loss_f, loss_pinn, rms_weighted_error\n",
    "from maestroflame.losses import log_loss, loss_mass_fraction, component_loss_f_L1, relative_loss\n",
    "from maestroflame.losses import derivative_loss_piecewise, signed_loss_function\n",
    "\n",
    "nnuc=13\n",
    "\n",
    "def criterion(data, pred, dXdt, actual):\n",
    "    #I still don't understand this one but i think don does\n",
    "    #loss1 = rms_weighted_error(pred, actual[:, :nnuc+1], actual[:, :nnuc+1])\n",
    "\n",
    "    # #difference in state variables vs prediction.\n",
    "    # loss1 = log_loss(pred, actual[:, :nnuc+1])\n",
    "    # #physics informed loss\n",
    "    # loss2 = loss_pinn(data, pred, actual, enuc_fac, enuc_dot_fac, log_option=True)\n",
    "    # #sum of mass fractions must be 1\n",
    "    # loss3 = loss_mass_fraction(pred)\n",
    "    # #relative loss function.\n",
    "    # loss4 = relative_loss(pred, actual[:, :nnuc+1])\n",
    "\n",
    "\n",
    "    #difference in state variables vs prediction.\n",
    "    loss1 = log_loss(pred, actual[:, :nnuc+1])\n",
    "    #scaled rates (pinn part) This only scales the magnitude of rates\n",
    "    loss2 = derivative_loss_piecewise(dXdt, actual[:, nnuc+1:], enuc_fac, enuc_dot_fac)\n",
    "    #L = nn.L1Loss()\n",
    "    #loss2 = L(dXdt, actual[:, nnuc+1:])\n",
    "\n",
    "    #here we learn the sign of rates to make up for not doing that in loss2\n",
    "    loss3 = signed_loss_function(dXdt, actual[:, nnuc+1:])\n",
    "    #relative loss function. Helps disginguish between same errors of different\n",
    "    #scales since we're scaling the loss2 so heavily\n",
    "    loss4 = relative_loss(pred, actual[:, :nnuc+1])\n",
    "    #sum of mass fractions must be 1\n",
    "    loss5 = loss_mass_fraction(pred)\n",
    "    #sum of rates must be 0\n",
    "    loss6 = loss_rates_mass_frac(dXdt, actual[:, nnuc+1:])\n",
    "\n",
    "    # loss_arr = [loss1.item(), loss2.item(), loss3.item(), loss4.item(), loss5.item()]\n",
    "    # return  loss1 + loss2 + loss3  + loss4 + loss5, loss_arr\n",
    "    loss_arr = [loss1.item(), loss2.item(), loss3.item(), loss5.item()]\n",
    "    return  loss1 + loss2 + loss3 + loss5, loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maestroflame.networks import Net\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_epochs = 2\n",
    "model = Net(16, 16, 16, 16, 14)\n",
    "\n",
    "# get model to cuda if possible\n",
    "model.to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "nrml.train(model,optimizer, num_epochs, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put model on cpu for plotting\n",
    "model.to(device=torch.device(\"cpu\"))\n",
    "\n",
    "nrml.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "plots = glob.glob('testing123/*.png')\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for plot in plots:\n",
    "    fig = Image(filename=(plot))\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
